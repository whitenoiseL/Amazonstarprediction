{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "import string\n",
    "import csv\n",
    "import nltk\n",
    "from sklearn.cluster import KMeans\n",
    "from math import pi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.corpus import wordnet, stopwords, sentiwordnet as swn\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('train_data.csv','r', errors='ignore')\n",
    "train_data = pd.read_csv(f,\n",
    "                header=0, sep=',',\n",
    "                parse_dates=['date', 'release_date', 'update_date'],\n",
    "                infer_datetime_format=True)\n",
    "length_train = len(train_data.review_text)\n",
    "\n",
    "f1 = open('test_data.csv','r', errors='ignore')\n",
    "test_data = pd.read_csv(f1,\n",
    "                header=0, sep=',',\n",
    "                parse_dates=['date', 'release_date', 'update_date'],\n",
    "                infer_datetime_format=True)\n",
    "length_test = len(test_data.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_review = pd.Series.tolist(train_data.review_text)\n",
    "train_rating = pd.Series.tolist(train_data.star_rating)\n",
    "# train_asin = pd.Series.tolist(train_data.asin)\n",
    "# train_app_purch = pd.Series.tolist(train_data.in_app_purchase)\n",
    "\n",
    "\n",
    "# train_asin1 = list(set(train_asin))\n",
    "# for i in range(len(train_asin)):\n",
    "#     for j in range(len(train_asin1)):\n",
    "#         if train_asin[i] == train_asin1[j]:\n",
    "#             train_asin[i] = j;\n",
    "\n",
    "# total_pack = zip(train_asin,train_app_purch,train_rating)\n",
    "# train_model2 = [None]*5\n",
    "train_model = [None]*5\n",
    "for i in range(5):\n",
    "    train_model[i] = [str(tmp) for tmp, score in zip(train_review, train_rating) if score == i+1]\n",
    "#     train_model2[i] = [[asin,app] for asin,app,score in total_pack if score == i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_word = [None]*5\n",
    "feature = [None]*5\n",
    "star_words = [None]*5\n",
    "#a = []\n",
    "test_review = pd.Series.tolist(test_data.review_text)\n",
    "test_review = [str(tmp) for tmp in test_review]\n",
    "voc_model = TfidfVectorizer(decode_error='ignore', max_df=0.8, min_df=0.01, stop_words='english')\n",
    "for i in range(5):\n",
    "    feature[i] = voc_model.fit_transform(train_model[i])\n",
    "    most_word[i] = voc_model.get_feature_names()\n",
    "# for i in range(5):\n",
    "#     for t,j in nltk.pos_tag(most_word[i]):\n",
    "#         if j in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']: \n",
    "#             a.append(t)\n",
    "#     star_words[i] = a\n",
    "            \n",
    "most_test_words = [None]*length_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# star_rate_predict = [None]*length_test\n",
    "# for m,sentence in enumerate(test_review):\n",
    "#     test_feature_words = []\n",
    "#     rate = 0\n",
    "#     for i,j in nltk.pos_tag(sentence):\n",
    "#         if j in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']: \n",
    "#             test_feature_words.append(i)\n",
    "#     for words in test_feature_words:\n",
    "#         for i in range(5):\n",
    "#             if words in star_words[i]:\n",
    "#                 rate = rate + i - 2\n",
    "#     star_rate_predict[m] = rate\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# test_view1 = [None]*\n",
    "# for i in range(len(test_review)):\n",
    "# #     if test_data1[i] == None:\n",
    "# #         test_data1[i] = the\n",
    "#     test_review1[i] = \"\".join([ch for ch in test_data1[i] if ch not in set(string.punctuation)])\n",
    "# #for i in range(5):\n",
    "# #     for j in range(len(most_word[i])):\n",
    "# test_review1 = [None]*len(test_review)       \n",
    "# for i in range(len(test_review)):\n",
    "#     test_review1[i] = ''.join(tmp for tmp in test_review if tmp not in set(string.punctuation))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.97746205329895\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "star_rate_predict = [None]*length_test\n",
    "for m,sentence in enumerate(test_review):\n",
    "    rate = 0\n",
    "    words = word_tokenize(sentence)\n",
    "    for w in words:\n",
    "        s = 0\n",
    "        rate_w = 0\n",
    "        for i in range(5):\n",
    "            if w.lower() in most_word[i]:\n",
    "                s = s + 1\n",
    "                rate_w = rate_w + i - 1\n",
    "        if s != 0:\n",
    "            rate_w = rate_w / s\n",
    "        rate = rate + rate_w\n",
    "    star_rate_predict[m] = rate\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters = 5)\n",
    "star = [[tmp] for tmp in star_rate_predict]\n",
    "# kmeans.fit(star)\n",
    "# centroids = kmeans.cluster_centers_\n",
    "# centroids1 = sorted(centroids)\n",
    "# print(centroids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standard = [[-1],[-0.5],[0],[1],[2]]\n",
    "distance = np.zeros((100000,5))\n",
    "for i in range(len(star_rate_predict)):\n",
    "    for j in range(5):\n",
    "        distance[i][j] = mean_squared_error(standard[j], star[i])\n",
    "        if distance[i][j] == 0:\n",
    "            distance[i][j] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01701677,  0.02316172,  0.03335287,  0.09264686,  0.83382178],\n",
       "       [ 0.15588272,  0.16914357,  0.18417145,  0.22092222,  0.26988005],\n",
       "       [ 0.04152151,  0.05423218,  0.07381602,  0.16608606,  0.66434422],\n",
       "       ..., \n",
       "       [ 0.1371781 ,  0.15379136,  0.17361603,  0.22676379,  0.30865072],\n",
       "       [ 0.15768132,  0.17054812,  0.18505655,  0.22023259,  0.26648143],\n",
       "       [ 0.11704977,  0.13575003,  0.15931774,  0.22941755,  0.35846492]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = np.zeros((100000,5))\n",
    "distance1 = 1/distance\n",
    "for i in range(100000):\n",
    "    for j in range(5):\n",
    "        prob[i][j] = (distance1[i][j]/sum(distance1[i]))\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob1 = prob.astype('str')\n",
    "review_id = pd.Series.tolist(test_data.review_id)\n",
    "review_id = np.asarray([[str(tmp)] for tmp in review_id])\n",
    "result = np.append(review_id, prob1, 1)\n",
    "title = np.asarray([['review_id','1-star','2-star','3-star','4-star','5-star']])\n",
    "result = np.append(title,result,0)\n",
    "#result = [np.array(tmp) for tmp in result]\n",
    "result = result.tolist()\n",
    "result = np.asarray(result)\n",
    "np.savetxt(\"result1.csv\",result,fmt='%s,%s,%s,%s,%s,%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
